=======================================================================
LLM Inference Simulator - TP Scaling Benchmark
=======================================================================
Start Time: 2025. 12. 08. (Ïõî) 13:27:57 PST
Random Seed: 12549

‚ö†Ô∏è  Note: Only TP (Tensor Parallelism) is implemented

Configuration:
  Model:           llama2-70b
  xPUs:            a100-80gb h100-80gb mi300x
  Arrival Rate:    10.0 req/s
  Duration:        60.0s

Testing 3 xPUs √ó 4 TP configs = 12 total tests
=======================================================================

-----------------------------------------------------------------------
[1/12] Testing: a100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[2/12] Testing: a100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 57

Throughput:
  Requests/sec: 0.95
  Tokens/sec: 125.09

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.99GB / 80GB (100.0%)
  P95:         79.64GB / 80GB ( 99.6%)
  P50 (Med):   75.43GB / 80GB ( 94.3%)

First Token Latency (seconds):
  Mean: 27.8169
  P50:  28.5765
  P90:  49.1773
  P95:  49.5146
  P99:  49.7102

End-to-End Latency (seconds):
  Mean: 29.6760
  P50:  29.5489
  P90:  46.5390
  P95:  48.2085
  P99:  52.2992

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/a100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 125.1 tok/s, Completed: 57, P95 TTFT: 49.51s

-----------------------------------------------------------------------
[3/12] Testing: a100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=62.35s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 179

Throughput:
  Requests/sec: 2.87
  Tokens/sec: 363.01

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.96GB / 80GB (100.0%)
  P95:         79.87GB / 80GB ( 99.8%)
  P50 (Med):   61.48GB / 80GB ( 76.9%)

First Token Latency (seconds):
  Mean: 20.0452
  P50:  18.2998
  P90:  35.6447
  P95:  36.3792
  P99:  37.8575

End-to-End Latency (seconds):
  Mean: 24.5317
  P50:  23.7857
  P90:  40.3819
  P95:  41.4392
  P99:  43.4169

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/a100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 363.0 tok/s, Completed: 179, P95 TTFT: 36.38s

-----------------------------------------------------------------------
[4/12] Testing: a100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.03s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 260

Throughput:
  Requests/sec: 4.33
  Tokens/sec: 557.84

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.52GB / 80GB ( 99.4%)
  P95:         79.10GB / 80GB ( 98.9%)
  P50 (Med):   52.70GB / 80GB ( 65.9%)

First Token Latency (seconds):
  Mean: 16.3668
  P50:  16.8718
  P90:  27.7222
  P95:  29.0881
  P99:  30.3994

End-to-End Latency (seconds):
  Mean: 18.8535
  P50:  19.0445
  P90:  29.6455
  P95:  30.9003
  P99:  32.0866

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/a100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 557.8 tok/s, Completed: 260, P95 TTFT: 29.09s

-----------------------------------------------------------------------
[5/12] Testing: h100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[6/12] Testing: h100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 108

Throughput:
  Requests/sec: 1.80
  Tokens/sec: 222.24

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.99GB / 80GB (100.0%)
  P95:         79.56GB / 80GB ( 99.4%)
  P50 (Med):   75.34GB / 80GB ( 94.2%)

First Token Latency (seconds):
  Mean: 25.7345
  P50:  25.9379
  P90:  44.6893
  P95:  47.8564
  P99:  48.1387

End-to-End Latency (seconds):
  Mean: 26.7350
  P50:  26.0508
  P90:  44.6736
  P95:  47.1532
  P99:  47.8099

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/h100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 222.2 tok/s, Completed: 108, P95 TTFT: 47.86s

-----------------------------------------------------------------------
[7/12] Testing: h100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 320

Throughput:
  Requests/sec: 5.33
  Tokens/sec: 699.71

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.87GB / 80GB ( 99.8%)
  P95:         79.38GB / 80GB ( 99.2%)
  P50 (Med):   62.82GB / 80GB ( 78.5%)

First Token Latency (seconds):
  Mean: 12.6071
  P50:  13.7172
  P90:  20.6815
  P95:  21.6916
  P99:  22.5388

End-to-End Latency (seconds):
  Mean: 14.6145
  P50:  15.6116
  P90:  22.0118
  P95:  23.3843
  P99:  24.5212

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/h100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 699.7 tok/s, Completed: 320, P95 TTFT: 21.69s

-----------------------------------------------------------------------
[8/12] Testing: h100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 469

Throughput:
  Requests/sec: 7.82
  Tokens/sec: 1025.37

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.20GB / 80GB ( 99.0%)
  P50 (Med):   52.31GB / 80GB ( 65.4%)

First Token Latency (seconds):
  Mean: 3.9280
  P50:  3.9725
  P90:  6.2846
  P95:  7.0799
  P99:  7.8293

End-to-End Latency (seconds):
  Mean: 6.4061
  P50:  6.6068
  P90:  9.0948
  P95:  9.5823
  P99:  10.7022

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/h100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1025.4 tok/s, Completed: 469, P95 TTFT: 7.08s

-----------------------------------------------------------------------
[9/12] Testing: mi300x - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 1 xPUs, arrival_rate=10.0 req/s
Memory: 130.39GB model, 61.61GB available for KV cache

Simulation completed at t=60.03s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 199

Throughput:
  Requests/sec: 3.32
  Tokens/sec: 451.16

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.73GB / 192GB ( 99.9%)
  P95:        191.55GB / 192GB ( 99.8%)
  P50 (Med):  172.38GB / 192GB ( 89.8%)

First Token Latency (seconds):
  Mean: 20.3698
  P50:  19.3376
  P90:  35.2732
  P95:  36.3567
  P99:  36.8566

End-to-End Latency (seconds):
  Mean: 22.6569
  P50:  22.0942
  P90:  35.9392
  P95:  37.6441
  P99:  39.4758

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/mi300x_1xpu_tp1.json
‚úì Completed successfully
  Throughput: 451.2 tok/s, Completed: 199, P95 TTFT: 36.36s

-----------------------------------------------------------------------
[10/12] Testing: mi300x - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 126.81GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 439

Throughput:
  Requests/sec: 7.32
  Tokens/sec: 959.10

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.21GB / 192GB ( 99.6%)
  P95:        190.60GB / 192GB ( 99.3%)
  P50 (Med):  127.31GB / 192GB ( 66.3%)

First Token Latency (seconds):
  Mean: 7.0064
  P50:  6.8394
  P90:  10.9210
  P95:  11.7252
  P99:  13.3723

End-to-End Latency (seconds):
  Mean: 10.7081
  P50:  10.7714
  P90:  15.1893
  P95:  15.9640
  P99:  17.7108

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/mi300x_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 959.1 tok/s, Completed: 439, P95 TTFT: 11.73s

-----------------------------------------------------------------------
[11/12] Testing: mi300x - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 159.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 509

Throughput:
  Requests/sec: 8.48
  Tokens/sec: 1109.72

xPU Utilization: 100.0%

Memory Usage:
  Peak:       105.56GB / 192GB ( 55.0%)
  P95:         96.71GB / 192GB ( 50.4%)
  P50 (Med):   63.76GB / 192GB ( 33.2%)

First Token Latency (seconds):
  Mean: 2.5112
  P50:  2.4245
  P90:  3.9821
  P95:  4.2870
  P99:  4.9962

End-to-End Latency (seconds):
  Mean: 4.4194
  P50:  4.4671
  P90:  6.2785
  P95:  6.6889
  P99:  7.1232

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/mi300x_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 1109.7 tok/s, Completed: 509, P95 TTFT: 4.29s

-----------------------------------------------------------------------
[12/12] Testing: mi300x - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 175.70GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 534

Throughput:
  Requests/sec: 8.90
  Tokens/sec: 1155.90

xPU Utilization: 100.0%

Memory Usage:
  Peak:        54.69GB / 192GB ( 28.5%)
  P95:         47.27GB / 192GB ( 24.6%)
  P50 (Med):   29.46GB / 192GB ( 15.3%)

First Token Latency (seconds):
  Mean: 1.0384
  P50:  0.9717
  P90:  1.7666
  P95:  1.9264
  P99:  2.3663

End-to-End Latency (seconds):
  Mean: 2.0306
  P50:  2.0312
  P90:  2.9212
  P95:  3.1617
  P99:  3.5401

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_132757/mi300x_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1155.9 tok/s, Completed: 534, P95 TTFT: 1.93s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (Ïõî) 13:28:04 PST

==============================================================================================================
TP SCALING BENCHMARK REPORT
==============================================================================================================

Configuration:
--------------------------------------------------------------------------------------------------------------
  Model:           llama2-70b
  xPUs Tested:     a100-80gb h100-80gb mi300x
  Workload:        10.0 req/s
  Duration:        60.0s

Performance by xPU and TP Configuration:
==============================================================================================================
xPU             #xPUs    TP     Status       Throughput         Completed    P95 TTFT    
--------------------------------------------------------------------------------------------------------------
a100-80gb       1        1      ‚ùå FAILED     N/A                N/A          N/A         
a100-80gb       2        2      ‚úÖ SUCCESS            125.1 tok/s     57/562      49.51s
a100-80gb       4        4      ‚úÖ SUCCESS            363.0 tok/s    179/562      36.38s
a100-80gb       8        8      ‚úÖ SUCCESS            557.8 tok/s    260/562      29.09s
h100-80gb       1        1      ‚ùå FAILED     N/A                N/A          N/A         
h100-80gb       2        2      ‚úÖ SUCCESS            222.2 tok/s    108/562      47.86s
h100-80gb       4        4      ‚úÖ SUCCESS            699.7 tok/s    320/562      21.69s
h100-80gb       8        8      ‚úÖ SUCCESS           1025.4 tok/s    469/562       7.08s
mi300x          1        1      ‚úÖ SUCCESS            451.2 tok/s    199/562      36.36s
mi300x          2        2      ‚úÖ SUCCESS            959.1 tok/s    439/562      11.73s
mi300x          4        4      ‚úÖ SUCCESS           1109.7 tok/s    509/562       4.29s
mi300x          8        8      ‚úÖ SUCCESS           1155.9 tok/s    534/562       1.93s
--------------------------------------------------------------------------------------------------------------

‚ùå Failed Tests:
--------------------------------------------------------------------------------------------------------------
  A100-80GB       TP=1 (1 xPUs):
    Reason: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

  H100-80GB       TP=1 (1 xPUs):
    Reason: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.


‚úÖ Successful Tests Summary:
--------------------------------------------------------------------------------------------------------------
  üèÜ Best Configuration:
     MI300X with TP=8 (8 xPUs)
     Throughput: 1155.9 tok/s
     Completed: 534/562 (95.0%)

  TP=8 Comparison:
    MI300X              1155.9 tok/s  (2.07x)
    H100-80GB           1025.4 tok/s  (1.84x)
    A100-80GB            557.8 tok/s  (1.00x)

  TP Scaling Efficiency:
    A100-80GB:
      TP= 4 (4 xPUs): 2.90x speedup, 145.1% efficiency (ideal: 2.0x)
      TP= 8 (8 xPUs): 4.46x speedup, 111.5% efficiency (ideal: 4.0x)

    H100-80GB:
      TP= 4 (4 xPUs): 3.15x speedup, 157.4% efficiency (ideal: 2.0x)
      TP= 8 (8 xPUs): 4.61x speedup, 115.3% efficiency (ideal: 4.0x)

    MI300X:
      TP= 2 (2 xPUs): 2.13x speedup, 106.3% efficiency (ideal: 2.0x)
      TP= 4 (4 xPUs): 2.46x speedup, 61.5% efficiency (ideal: 4.0x)
      TP= 8 (8 xPUs): 2.56x speedup, 32.0% efficiency (ideal: 8.0x)

==============================================================================================================
Total: 10 succeeded, 2 failed
==============================================================================================================

Results saved to: results/cluster_benchmark_20251208_132757
=======================================================================
