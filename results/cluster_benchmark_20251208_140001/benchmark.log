=======================================================================
LLM Inference Simulator - TP Scaling Benchmark
=======================================================================
Start Time: 2025. 12. 08. (Ïõî) 14:00:01 PST
Random Seed: 5115

‚ö†Ô∏è  Note: Only TP (Tensor Parallelism) is implemented

Configuration:
  Model:           llama2-70b
  xPUs:            a100-80gb h100-80gb mi300x
  Arrival Rate:    10.0 req/s
  Duration:        60.0s

Testing 3 xPUs √ó 4 TP configs = 12 total tests
=======================================================================

-----------------------------------------------------------------------
[1/12] Testing: a100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[2/12] Testing: a100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 52

Throughput:
  Requests/sec: 0.87
  Tokens/sec: 122.51

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.95GB / 80GB ( 99.9%)
  P50 (Med):   75.02GB / 80GB ( 93.8%)

First Token Latency (seconds):
  Mean: 27.3253
  P50:  27.7678
  P90:  51.4497
  P95:  51.9865
  P99:  52.5046

End-to-End Latency (seconds):
  Mean: 27.8572
  P50:  28.0576
  P90:  46.4621
  P95:  49.5459
  P99:  51.5371

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/a100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 122.5 tok/s, Completed: 52, P95 TTFT: 51.99s

-----------------------------------------------------------------------
[3/12] Testing: a100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 174

Throughput:
  Requests/sec: 2.90
  Tokens/sec: 391.54

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.79GB / 80GB ( 99.7%)
  P95:         79.60GB / 80GB ( 99.5%)
  P50 (Med):   66.84GB / 80GB ( 83.6%)

First Token Latency (seconds):
  Mean: 20.0848
  P50:  19.1574
  P90:  36.0858
  P95:  36.6847
  P99:  37.5170

End-to-End Latency (seconds):
  Mean: 23.2049
  P50:  23.1046
  P90:  36.1635
  P95:  40.2272
  P99:  41.1157

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/a100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 391.5 tok/s, Completed: 174, P95 TTFT: 36.68s

-----------------------------------------------------------------------
[4/12] Testing: a100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=61.83s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 269

Throughput:
  Requests/sec: 4.35
  Tokens/sec: 564.77

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.93GB / 80GB ( 99.9%)
  P95:         79.66GB / 80GB ( 99.6%)
  P50 (Med):   55.32GB / 80GB ( 69.1%)

First Token Latency (seconds):
  Mean: 14.2014
  P50:  13.5524
  P90:  26.9531
  P95:  27.7070
  P99:  28.3972

End-to-End Latency (seconds):
  Mean: 18.6294
  P50:  18.0308
  P90:  32.0832
  P95:  33.1960
  P99:  34.9791

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/a100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 564.8 tok/s, Completed: 269, P95 TTFT: 27.71s

-----------------------------------------------------------------------
[5/12] Testing: h100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[6/12] Testing: h100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 100

Throughput:
  Requests/sec: 1.67
  Tokens/sec: 219.01

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.47GB / 80GB ( 99.3%)
  P50 (Med):   75.03GB / 80GB ( 93.8%)

First Token Latency (seconds):
  Mean: 24.0858
  P50:  25.9847
  P90:  42.2675
  P95:  45.1806
  P99:  45.6646

End-to-End Latency (seconds):
  Mean: 25.7809
  P50:  26.9093
  P90:  44.0249
  P95:  44.9465
  P99:  46.5985

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/h100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 219.0 tok/s, Completed: 100, P95 TTFT: 45.18s

-----------------------------------------------------------------------
[7/12] Testing: h100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 326

Throughput:
  Requests/sec: 5.43
  Tokens/sec: 701.95

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.99GB / 80GB (100.0%)
  P95:         79.55GB / 80GB ( 99.4%)
  P50 (Med):   63.31GB / 80GB ( 79.1%)

First Token Latency (seconds):
  Mean: 12.9164
  P50:  11.7663
  P90:  24.7006
  P95:  25.9417
  P99:  27.2690

End-to-End Latency (seconds):
  Mean: 14.5631
  P50:  13.5999
  P90:  25.9565
  P95:  27.0039
  P99:  28.1826

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/h100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 702.0 tok/s, Completed: 326, P95 TTFT: 25.94s

-----------------------------------------------------------------------
[8/12] Testing: h100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 452

Throughput:
  Requests/sec: 7.53
  Tokens/sec: 1017.06

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.80GB / 80GB ( 99.8%)
  P95:         79.29GB / 80GB ( 99.1%)
  P50 (Med):   47.81GB / 80GB ( 59.8%)

First Token Latency (seconds):
  Mean: 5.9874
  P50:  6.2992
  P90:  10.7336
  P95:  11.6567
  P99:  12.7089

End-to-End Latency (seconds):
  Mean: 8.1883
  P50:  8.0575
  P90:  13.1856
  P95:  13.8385
  P99:  15.4691

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/h100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1017.1 tok/s, Completed: 452, P95 TTFT: 11.66s

-----------------------------------------------------------------------
[9/12] Testing: mi300x - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 1 xPUs, arrival_rate=10.0 req/s
Memory: 130.39GB model, 61.61GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 209

Throughput:
  Requests/sec: 3.48
  Tokens/sec: 470.83

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.90GB / 192GB ( 99.9%)
  P95:        191.39GB / 192GB ( 99.7%)
  P50 (Med):  172.05GB / 192GB ( 89.6%)

First Token Latency (seconds):
  Mean: 19.5639
  P50:  19.0034
  P90:  34.3240
  P95:  35.3884
  P99:  35.8457

End-to-End Latency (seconds):
  Mean: 21.7115
  P50:  22.1175
  P90:  33.3170
  P95:  34.7620
  P99:  38.3103

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/mi300x_1xpu_tp1.json
‚úì Completed successfully
  Throughput: 470.8 tok/s, Completed: 209, P95 TTFT: 35.39s

-----------------------------------------------------------------------
[10/12] Testing: mi300x - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 126.81GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 421

Throughput:
  Requests/sec: 7.01
  Tokens/sec: 954.01

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.85GB / 192GB ( 99.9%)
  P95:        191.66GB / 192GB ( 99.8%)
  P50 (Med):  125.71GB / 192GB ( 65.5%)

First Token Latency (seconds):
  Mean: 9.0454
  P50:  9.1452
  P90:  15.3159
  P95:  16.5044
  P99:  17.3064

End-to-End Latency (seconds):
  Mean: 12.3916
  P50:  12.6850
  P90:  18.7381
  P95:  19.9575
  P99:  21.7321

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/mi300x_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 954.0 tok/s, Completed: 421, P95 TTFT: 16.50s

-----------------------------------------------------------------------
[11/12] Testing: mi300x - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 159.40GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 540

Throughput:
  Requests/sec: 9.00
  Tokens/sec: 1176.56

xPU Utilization: 100.0%

Memory Usage:
  Peak:       130.26GB / 192GB ( 67.8%)
  P95:        109.13GB / 192GB ( 56.8%)
  P50 (Med):   63.69GB / 192GB ( 33.2%)

First Token Latency (seconds):
  Mean: 2.9827
  P50:  2.8669
  P90:  5.0510
  P95:  5.5846
  P99:  6.5117

End-to-End Latency (seconds):
  Mean: 5.1876
  P50:  5.0342
  P90:  7.7716
  P95:  8.4205
  P99:  9.4841

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/mi300x_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 1176.6 tok/s, Completed: 540, P95 TTFT: 5.58s

-----------------------------------------------------------------------
[12/12] Testing: mi300x - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 175.70GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 571
  Completed: 556

Throughput:
  Requests/sec: 9.27
  Tokens/sec: 1212.13

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.32GB / 192GB ( 41.3%)
  P95:         52.77GB / 192GB ( 27.5%)
  P50 (Med):   31.04GB / 192GB ( 16.2%)

First Token Latency (seconds):
  Mean: 1.1925
  P50:  1.0687
  P90:  2.1263
  P95:  2.3831
  P99:  3.0258

End-to-End Latency (seconds):
  Mean: 2.3137
  P50:  2.2173
  P90:  3.4720
  P95:  3.9831
  P99:  4.9382

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_140001/mi300x_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1212.1 tok/s, Completed: 556, P95 TTFT: 2.38s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (Ïõî) 14:00:08 PST

==================================================================================================================================
TP SCALING BENCHMARK REPORT
==================================================================================================================================

Configuration:
----------------------------------------------------------------------------------------------------------------------------------
  Model:           N/A
  xPUs Tested:     N/A
  Workload:        N/A req/s
  Duration:        N/As

Performance & Cost Analysis:
==================================================================================================================================
xPU           GPUs  TP Status      Throughput  P95 TTFT   $/hour   Tok/$/h   $/1M tok
----------------------------------------------------------------------------------------------------------------------------------
A100-80GB        1   1 ‚ùå FAIL             N/A       N/A      N/A       N/A        N/A
A100-80GB        2   2 ‚úÖ OK          122.5 tok/s    51.99s $   7.34      16.7 $ 59912.61
A100-80GB        4   4 ‚úÖ OK          391.5 tok/s    36.68s $  14.68      26.7 $ 37493.21
A100-80GB        8   8 ‚úÖ OK          564.8 tok/s    27.71s $  29.36      19.2 $ 51985.40
H100-80GB        1   1 ‚ùå FAIL             N/A       N/A      N/A       N/A        N/A
H100-80GB        2   2 ‚úÖ OK          219.0 tok/s    45.18s $  12.98      16.9 $ 59266.72
H100-80GB        4   4 ‚úÖ OK          702.0 tok/s    25.94s $  25.96      27.0 $ 36982.58
H100-80GB        8   8 ‚úÖ OK         1017.1 tok/s    11.66s $  51.92      19.6 $ 51048.88
MI300X           1   1 ‚úÖ OK          470.8 tok/s    35.39s $   7.00      67.3 $ 14867.29
MI300X           2   2 ‚úÖ OK          954.0 tok/s    16.50s $  14.00      68.1 $ 14674.85
MI300X           4   4 ‚úÖ OK         1176.6 tok/s     5.58s $  28.00      42.0 $ 23798.27
MI300X           8   8 ‚úÖ OK         1212.1 tok/s     2.38s $  56.00      21.6 $ 46199.54
----------------------------------------------------------------------------------------------------------------------------------

üèÜ Recommended Configurations:
----------------------------------------------------------------------------------------------------------------------------------
  üí∞ Best Value (tok/$/hour):
     MI300X: 2 GPUs, TP=2
     68.1 tok/$/hour | $14674.85/1M tokens | 954.0 tok/s

  üöÄ Best Performance (throughput):
     MI300X: 8 GPUs, TP=8
     1212.1 tok/s | $56.00/hour | P95 TTFT: 2.38s

  ‚ö° Best Latency (TTFT):
     MI300X: 8 GPUs, TP=8
     P95 TTFT: 2.38s | 1212.1 tok/s | $56.00/hour


‚ùå Failed Tests:
----------------------------------------------------------------------------------------------------------------------------------
  A100-80GB: 1 GPUs, TP=1
    ‚Üí 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
  H100-80GB: 1 GPUs, TP=1
    ‚Üí 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.


üìà TP Scaling Efficiency:
----------------------------------------------------------------------------------------------------------------------------------
  A100-80GB (baseline: 2 GPU, TP=2, 122.5 tok/s):
    4 GPUs, TP=4: 3.20x speedup (159.8% efficiency, ideal: 2.0x)
    8 GPUs, TP=8: 4.61x speedup (115.2% efficiency, ideal: 4.0x)

  H100-80GB (baseline: 2 GPU, TP=2, 219.0 tok/s):
    4 GPUs, TP=4: 3.21x speedup (160.3% efficiency, ideal: 2.0x)
    8 GPUs, TP=8: 4.64x speedup (116.1% efficiency, ideal: 4.0x)

  MI300X (baseline: 1 GPU, TP=1, 470.8 tok/s):
    2 GPUs, TP=2: 2.03x speedup (101.3% efficiency, ideal: 2.0x)
    4 GPUs, TP=4: 2.50x speedup (62.5% efficiency, ideal: 4.0x)
    8 GPUs, TP=8: 2.57x speedup (32.2% efficiency, ideal: 8.0x)

==================================================================================================================================
Summary: 10 succeeded, 2 failed
==================================================================================================================================

Results saved to: results/cluster_benchmark_20251208_140001
=======================================================================
