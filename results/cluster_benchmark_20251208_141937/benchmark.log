=======================================================================
LLM Inference Simulator - TP Scaling Benchmark
=======================================================================
Start Time: 2025. 12. 08. (Ïõî) 14:19:37 PST
Random Seed: 19005

‚ö†Ô∏è  Note: Only TP (Tensor Parallelism) is implemented

Configuration:
  Model:           llama2-70b
  xPUs:            a100-80gb h100-80gb mi300x
  Arrival Rate:    10.0 req/s
  Duration:        60.0s

Testing 3 xPUs √ó 4 TP configs = 12 total tests
=======================================================================

-----------------------------------------------------------------------
[1/12] Testing: a100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 212, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[2/12] Testing: a100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 59

Throughput:
  Requests/sec: 0.98
  Tokens/sec: 129.60

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.86GB / 80GB ( 99.8%)
  P95:         79.82GB / 80GB ( 99.8%)
  P50 (Med):   75.61GB / 80GB ( 94.5%)

First Token Latency (seconds):
  Mean: 24.9532
  P50:  25.2702
  P90:  47.1497
  P95:  47.6123
  P99:  47.9244

End-to-End Latency (seconds):
  Mean: 28.1670
  P50:  28.5876
  P90:  47.8836
  P95:  52.3965
  P99:  53.1418

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/a100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 129.6 tok/s, Completed: 59, P95 TTFT: 47.61s

-----------------------------------------------------------------------
[3/12] Testing: a100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.04s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 164

Throughput:
  Requests/sec: 2.73
  Tokens/sec: 382.78

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.73GB / 80GB ( 99.7%)
  P50 (Med):   66.01GB / 80GB ( 82.5%)

First Token Latency (seconds):
  Mean: 21.6424
  P50:  20.2091
  P90:  39.3192
  P95:  40.1347
  P99:  40.8298

End-to-End Latency (seconds):
  Mean: 23.0796
  P50:  24.1055
  P90:  38.5209
  P95:  40.0654
  P99:  42.6049

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/a100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 382.8 tok/s, Completed: 164, P95 TTFT: 40.13s

-----------------------------------------------------------------------
[4/12] Testing: a100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 261

Throughput:
  Requests/sec: 4.35
  Tokens/sec: 572.75

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.88GB / 80GB ( 99.8%)
  P95:         79.69GB / 80GB ( 99.6%)
  P50 (Med):   56.18GB / 80GB ( 70.2%)

First Token Latency (seconds):
  Mean: 16.4609
  P50:  16.9607
  P90:  29.6002
  P95:  30.5141
  P99:  31.7787

End-to-End Latency (seconds):
  Mean: 20.2577
  P50:  20.8631
  P90:  33.0069
  P95:  34.5552
  P99:  35.4269

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/a100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 572.7 tok/s, Completed: 261, P95 TTFT: 30.51s

-----------------------------------------------------------------------
[5/12] Testing: h100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 212, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[6/12] Testing: h100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 103

Throughput:
  Requests/sec: 1.72
  Tokens/sec: 230.86

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.86GB / 80GB ( 99.8%)
  P95:         79.72GB / 80GB ( 99.6%)
  P50 (Med):   75.53GB / 80GB ( 94.4%)

First Token Latency (seconds):
  Mean: 23.4122
  P50:  21.5186
  P90:  42.9956
  P95:  47.0206
  P99:  47.3362

End-to-End Latency (seconds):
  Mean: 25.8354
  P50:  25.1520
  P90:  46.4789
  P95:  48.5559
  P99:  49.7960

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/h100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 230.9 tok/s, Completed: 103, P95 TTFT: 47.02s

-----------------------------------------------------------------------
[7/12] Testing: h100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 321

Throughput:
  Requests/sec: 5.35
  Tokens/sec: 688.77

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.78GB / 80GB ( 99.7%)
  P95:         79.55GB / 80GB ( 99.4%)
  P50 (Med):   61.36GB / 80GB ( 76.7%)

First Token Latency (seconds):
  Mean: 13.8919
  P50:  14.1996
  P90:  23.4598
  P95:  24.5120
  P99:  25.6042

End-to-End Latency (seconds):
  Mean: 16.5619
  P50:  16.9487
  P90:  25.7922
  P95:  27.3279
  P99:  29.1329

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/h100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 688.8 tok/s, Completed: 321, P95 TTFT: 24.51s

-----------------------------------------------------------------------
[8/12] Testing: h100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 467

Throughput:
  Requests/sec: 7.78
  Tokens/sec: 981.03

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.70GB / 80GB ( 99.6%)
  P95:         79.23GB / 80GB ( 99.0%)
  P50 (Med):   49.33GB / 80GB ( 61.7%)

First Token Latency (seconds):
  Mean: 7.0354
  P50:  7.2391
  P90:  11.4295
  P95:  12.4195
  P99:  13.8521

End-to-End Latency (seconds):
  Mean: 9.1336
  P50:  9.5730
  P90:  13.3328
  P95:  13.9337
  P99:  15.5149

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/h100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 981.0 tok/s, Completed: 467, P95 TTFT: 12.42s

-----------------------------------------------------------------------
[9/12] Testing: mi300x - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 1 xPUs, arrival_rate=10.0 req/s
Memory: 130.39GB model, 61.61GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 198

Throughput:
  Requests/sec: 3.30
  Tokens/sec: 445.49

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.79GB / 192GB ( 99.9%)
  P95:        191.39GB / 192GB ( 99.7%)
  P50 (Med):  169.13GB / 192GB ( 88.1%)

First Token Latency (seconds):
  Mean: 21.1523
  P50:  20.6591
  P90:  37.9087
  P95:  39.3466
  P99:  40.2577

End-to-End Latency (seconds):
  Mean: 22.0097
  P50:  22.0673
  P90:  35.7510
  P95:  36.9974
  P99:  38.8356

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/mi300x_1xpu_tp1.json
‚úì Completed successfully
  Throughput: 445.5 tok/s, Completed: 198, P95 TTFT: 39.35s

-----------------------------------------------------------------------
[10/12] Testing: mi300x - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 126.81GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 414

Throughput:
  Requests/sec: 6.90
  Tokens/sec: 909.29

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.22GB / 192GB ( 99.6%)
  P95:        190.85GB / 192GB ( 99.4%)
  P50 (Med):  126.73GB / 192GB ( 66.0%)

First Token Latency (seconds):
  Mean: 9.5554
  P50:  9.9901
  P90:  14.9393
  P95:  16.0869
  P99:  17.5121

End-to-End Latency (seconds):
  Mean: 12.3963
  P50:  12.9763
  P90:  18.0299
  P95:  18.8688
  P99:  19.7015

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/mi300x_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 909.3 tok/s, Completed: 414, P95 TTFT: 16.09s

-----------------------------------------------------------------------
[11/12] Testing: mi300x - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 159.40GB available for KV cache

Simulation completed at t=60.68s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 553

Throughput:
  Requests/sec: 9.11
  Tokens/sec: 1151.70

xPU Utilization: 100.0%

Memory Usage:
  Peak:       126.65GB / 192GB ( 66.0%)
  P95:        122.25GB / 192GB ( 63.7%)
  P50 (Med):   68.27GB / 192GB ( 35.6%)

First Token Latency (seconds):
  Mean: 3.3078
  P50:  3.2325
  P90:  5.3440
  P95:  5.7070
  P99:  6.5040

End-to-End Latency (seconds):
  Mean: 5.6288
  P50:  5.6359
  P90:  8.1314
  P95:  8.7730
  P99:  9.4076

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/mi300x_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 1151.7 tok/s, Completed: 553, P95 TTFT: 5.71s

-----------------------------------------------------------------------
[12/12] Testing: mi300x - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 175.70GB available for KV cache

Simulation completed at t=60.05s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 618
  Completed: 595

Throughput:
  Requests/sec: 9.91
  Tokens/sec: 1247.90

xPU Utilization: 100.0%

Memory Usage:
  Peak:        67.08GB / 192GB ( 34.9%)
  P95:         62.02GB / 192GB ( 32.3%)
  P50 (Med):   34.66GB / 192GB ( 18.1%)

First Token Latency (seconds):
  Mean: 1.4421
  P50:  1.3781
  P90:  2.4604
  P95:  2.7315
  P99:  3.1037

End-to-End Latency (seconds):
  Mean: 2.6635
  P50:  2.6115
  P90:  3.8923
  P95:  4.2015
  P99:  4.7894

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_141937/mi300x_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1247.9 tok/s, Completed: 595, P95 TTFT: 2.73s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (Ïõî) 14:19:44 PST

=============================================================================================================================
TP SCALING BENCHMARK REPORT
=============================================================================================================================

Configuration:
-----------------------------------------------------------------------------------------------------------------------------
  Model:           N/A
  xPUs Tested:     N/A
  Workload:        N/A req/s
  Duration:        N/As

Performance & Cost Analysis:
=============================================================================================================================
         xPU  GPUs  TP   Status  Throughput  P95 TTFT     Cost  Efficiency        Cost
                                    (tok/s)     (sec)   ($/hr)   (tok/$/h)   ($/1Mtok)
-----------------------------------------------------------------------------------------------------------------------------
   A100-80GB     1   1   ‚ùå FAIL         N/A       N/A      N/A         N/A         N/A
   A100-80GB     2   2     ‚úÖ OK       129.6     47.61     7.34        17.7    56633.67
   A100-80GB     4   4     ‚úÖ OK       382.8     40.13    14.68        26.1    38350.80
   A100-80GB     8   8     ‚úÖ OK       572.7     30.51    29.36        19.5    51261.56
   H100-80GB     1   1   ‚ùå FAIL         N/A       N/A      N/A         N/A         N/A
   H100-80GB     2   2     ‚úÖ OK       230.9     47.02    12.98        17.8    56224.18
   H100-80GB     4   4     ‚úÖ OK       688.8     24.51    25.96        26.5    37690.57
   H100-80GB     8   8     ‚úÖ OK       981.0     12.42    51.92        18.9    52923.82
      MI300X     1   1     ‚úÖ OK       445.5     39.35     7.00        63.6    15713.16
      MI300X     2   2     ‚úÖ OK       909.3     16.09    14.00        64.9    15396.63
      MI300X     4   4     ‚úÖ OK      1151.7      5.71    28.00        41.1    24311.84
      MI300X     8   8     ‚úÖ OK      1247.9      2.73    56.00        22.3    44875.55
-----------------------------------------------------------------------------------------------------------------------------

üèÜ Recommended Configurations:
-----------------------------------------------------------------------------------------------------------------------------
  üí∞ Best Value (tok/$/hour):
     MI300X: 2 GPUs, TP=2
     64.9 tok/$/hour | $15396.63/1M tokens | 909.3 tok/s

  üöÄ Best Performance (throughput):
     MI300X: 8 GPUs, TP=8
     1247.9 tok/s | $56.00/hour | P95 TTFT: 2.73s

  ‚ö° Best Latency (TTFT):
     MI300X: 8 GPUs, TP=8
     P95 TTFT: 2.73s | 1247.9 tok/s | $56.00/hour


‚ùå Failed Tests:
-----------------------------------------------------------------------------------------------------------------------------
  A100-80GB: 1 GPUs, TP=1
    ‚Üí 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
  H100-80GB: 1 GPUs, TP=1
    ‚Üí 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.


üìà TP Scaling Efficiency:
-----------------------------------------------------------------------------------------------------------------------------
  A100-80GB (baseline: 2 GPU, TP=2, 129.6 tok/s):
    4 GPUs, TP=4: 2.95x speedup (147.7% efficiency, ideal: 2.0x)
    8 GPUs, TP=8: 4.42x speedup (110.5% efficiency, ideal: 4.0x)

  H100-80GB (baseline: 2 GPU, TP=2, 230.9 tok/s):
    4 GPUs, TP=4: 2.98x speedup (149.2% efficiency, ideal: 2.0x)
    8 GPUs, TP=8: 4.25x speedup (106.2% efficiency, ideal: 4.0x)

  MI300X (baseline: 1 GPU, TP=1, 445.5 tok/s):
    2 GPUs, TP=2: 2.04x speedup (102.1% efficiency, ideal: 2.0x)
    4 GPUs, TP=4: 2.59x speedup (64.6% efficiency, ideal: 4.0x)
    8 GPUs, TP=8: 2.80x speedup (35.0% efficiency, ideal: 8.0x)

=============================================================================================================================
Summary: 10 succeeded, 2 failed
=============================================================================================================================

Results saved to: results/cluster_benchmark_20251208_141937
=======================================================================
