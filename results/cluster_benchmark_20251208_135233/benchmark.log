=======================================================================
LLM Inference Simulator - TP Scaling Benchmark
=======================================================================
Start Time: 2025. 12. 08. (월) 13:52:33 PST
Random Seed: 13470

⚠️  Note: Only TP (Tensor Parallelism) is implemented

Configuration:
  Model:           llama2-70b
  xPUs:            a100-80gb h100-80gb mi300x
  Arrival Rate:    10.0 req/s
  Duration:        60.0s

Testing 3 xPUs × 4 TP configs = 12 total tests
=======================================================================

-----------------------------------------------------------------------
[1/12] Testing: a100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
✗ Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[2/12] Testing: a100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.97s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 49

Throughput:
  Requests/sec: 0.80
  Tokens/sec: 116.98

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.92GB / 80GB ( 99.9%)
  P95:         79.31GB / 80GB ( 99.1%)
  P50 (Med):   75.65GB / 80GB ( 94.6%)

First Token Latency (seconds):
  Mean: 26.1881
  P50:  22.7193
  P90:  48.0988
  P95:  48.2366
  P99:  48.3934

End-to-End Latency (seconds):
  Mean: 31.3229
  P50:  30.9040
  P90:  52.1262
  P95:  54.1242
  P99:  55.1501

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/a100-80gb_2xpu_tp2.json
✓ Completed successfully
  Throughput: 117.0 tok/s, Completed: 49, P95 TTFT: 48.24s

-----------------------------------------------------------------------
[3/12] Testing: a100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=62.15s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 170

Throughput:
  Requests/sec: 2.74
  Tokens/sec: 379.39

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.93GB / 80GB ( 99.9%)
  P95:         78.82GB / 80GB ( 98.5%)
  P50 (Med):   66.88GB / 80GB ( 83.6%)

First Token Latency (seconds):
  Mean: 20.2804
  P50:  22.8891
  P90:  35.7503
  P95:  36.6911
  P99:  37.5856

End-to-End Latency (seconds):
  Mean: 25.1030
  P50:  24.2321
  P90:  40.9332
  P95:  43.2035
  P99:  44.2659

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/a100-80gb_4xpu_tp4.json
✓ Completed successfully
  Throughput: 379.4 tok/s, Completed: 170, P95 TTFT: 36.69s

-----------------------------------------------------------------------
[4/12] Testing: a100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 251

Throughput:
  Requests/sec: 4.18
  Tokens/sec: 570.48

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.07GB / 80GB ( 98.8%)
  P50 (Med):   56.21GB / 80GB ( 70.3%)

First Token Latency (seconds):
  Mean: 17.4541
  P50:  17.5804
  P90:  29.7178
  P95:  31.0030
  P99:  32.4494

End-to-End Latency (seconds):
  Mean: 19.9926
  P50:  20.5399
  P90:  31.2660
  P95:  32.5530
  P99:  33.8609

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/a100-80gb_8xpu_tp8.json
✓ Completed successfully
  Throughput: 570.5 tok/s, Completed: 251, P95 TTFT: 31.00s

-----------------------------------------------------------------------
[5/12] Testing: h100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
✗ Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[6/12] Testing: h100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 94

Throughput:
  Requests/sec: 1.57
  Tokens/sec: 216.77

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.96GB / 80GB ( 99.9%)
  P95:         79.36GB / 80GB ( 99.2%)
  P50 (Med):   75.67GB / 80GB ( 94.6%)

First Token Latency (seconds):
  Mean: 27.7481
  P50:  29.4488
  P90:  46.2912
  P95:  49.9325
  P99:  50.3750

End-to-End Latency (seconds):
  Mean: 29.0546
  P50:  30.2172
  P90:  47.2622
  P95:  49.4415
  P99:  50.3187

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/h100-80gb_2xpu_tp2.json
✓ Completed successfully
  Throughput: 216.8 tok/s, Completed: 94, P95 TTFT: 49.93s

-----------------------------------------------------------------------
[7/12] Testing: h100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 308

Throughput:
  Requests/sec: 5.13
  Tokens/sec: 713.10

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.78GB / 80GB ( 99.7%)
  P95:         79.23GB / 80GB ( 99.0%)
  P50 (Med):   62.19GB / 80GB ( 77.7%)

First Token Latency (seconds):
  Mean: 13.8842
  P50:  14.2616
  P90:  23.0360
  P95:  24.3615
  P99:  25.9699

End-to-End Latency (seconds):
  Mean: 15.8935
  P50:  16.6576
  P90:  24.3994
  P95:  25.3808
  P99:  26.9623

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/h100-80gb_4xpu_tp4.json
✓ Completed successfully
  Throughput: 713.1 tok/s, Completed: 308, P95 TTFT: 24.36s

-----------------------------------------------------------------------
[8/12] Testing: h100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 470

Throughput:
  Requests/sec: 7.83
  Tokens/sec: 1037.87

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.00GB / 80GB ( 98.7%)
  P50 (Med):   53.63GB / 80GB ( 67.0%)

First Token Latency (seconds):
  Mean: 5.6630
  P50:  5.2379
  P90:  10.0239
  P95:  11.2119
  P99:  12.8837

End-to-End Latency (seconds):
  Mean: 8.4086
  P50:  8.0829
  P90:  12.8739
  P95:  13.9417
  P99:  15.9893

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/h100-80gb_8xpu_tp8.json
✓ Completed successfully
  Throughput: 1037.9 tok/s, Completed: 470, P95 TTFT: 11.21s

-----------------------------------------------------------------------
[9/12] Testing: mi300x - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 1 xPUs, arrival_rate=10.0 req/s
Memory: 130.39GB model, 61.61GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 209

Throughput:
  Requests/sec: 3.48
  Tokens/sec: 483.29

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.77GB / 192GB ( 99.9%)
  P95:        191.50GB / 192GB ( 99.7%)
  P50 (Med):  172.77GB / 192GB ( 90.0%)

First Token Latency (seconds):
  Mean: 19.2542
  P50:  19.3617
  P90:  32.7348
  P95:  34.4902
  P99:  35.3090

End-to-End Latency (seconds):
  Mean: 23.1548
  P50:  23.1784
  P90:  36.0470
  P95:  37.7858
  P99:  39.7906

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/mi300x_1xpu_tp1.json
✓ Completed successfully
  Throughput: 483.3 tok/s, Completed: 209, P95 TTFT: 34.49s

-----------------------------------------------------------------------
[10/12] Testing: mi300x - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 126.81GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 439

Throughput:
  Requests/sec: 7.32
  Tokens/sec: 977.89

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.89GB / 192GB ( 99.9%)
  P95:        190.79GB / 192GB ( 99.4%)
  P50 (Med):  132.10GB / 192GB ( 68.8%)

First Token Latency (seconds):
  Mean: 8.2319
  P50:  8.1033
  P90:  13.1225
  P95:  14.3717
  P99:  15.7933

End-to-End Latency (seconds):
  Mean: 12.1542
  P50:  12.0496
  P90:  17.5435
  P95:  18.9214
  P99:  20.4122

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/mi300x_2xpu_tp2.json
✓ Completed successfully
  Throughput: 977.9 tok/s, Completed: 439, P95 TTFT: 14.37s

-----------------------------------------------------------------------
[11/12] Testing: mi300x - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 159.40GB available for KV cache

Simulation completed at t=61.08s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 546

Throughput:
  Requests/sec: 8.94
  Tokens/sec: 1182.14

xPU Utilization: 100.0%

Memory Usage:
  Peak:       134.69GB / 192GB ( 70.2%)
  P95:        123.45GB / 192GB ( 64.3%)
  P50 (Med):   71.74GB / 192GB ( 37.4%)

First Token Latency (seconds):
  Mean: 3.0457
  P50:  2.9430
  P90:  4.9159
  P95:  5.4625
  P99:  6.4869

End-to-End Latency (seconds):
  Mean: 5.3792
  P50:  5.2665
  P90:  7.8149
  P95:  8.4294
  P99:  9.8110

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/mi300x_4xpu_tp4.json
✓ Completed successfully
  Throughput: 1182.1 tok/s, Completed: 546, P95 TTFT: 5.46s

-----------------------------------------------------------------------
[12/12] Testing: mi300x - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 175.70GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 616
  Completed: 585

Throughput:
  Requests/sec: 9.75
  Tokens/sec: 1283.83

xPU Utilization: 100.0%

Memory Usage:
  Peak:        75.02GB / 192GB ( 39.1%)
  P95:         60.88GB / 192GB ( 31.7%)
  P50 (Med):   35.64GB / 192GB ( 18.6%)

First Token Latency (seconds):
  Mean: 1.3237
  P50:  1.3058
  P90:  2.2027
  P95:  2.4473
  P99:  2.9874

End-to-End Latency (seconds):
  Mean: 2.5278
  P50:  2.4962
  P90:  3.6317
  P95:  4.0011
  P99:  4.5814

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_135233/mi300x_8xpu_tp8.json
✓ Completed successfully
  Throughput: 1283.8 tok/s, Completed: 585, P95 TTFT: 2.45s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (월) 13:52:39 PST


Results saved to: results/cluster_benchmark_20251208_135233
=======================================================================
