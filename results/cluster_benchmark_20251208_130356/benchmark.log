=======================================================================
LLM Inference Simulator - Cluster Configuration Benchmark
=======================================================================
Start Time: 2025. 12. 08. (월) 13:03:56 PST
Random Seed: 4088

Configuration:
  Model:           llama2-70b
  xPU:             a100-80gb
  Arrival Rate:    10.0 req/s
  Input Length:    avg=512, max=1024
  Output Length:   avg=128, max=256
  Duration:        60.0s

Testing 6 cluster configurations...
=======================================================================

-----------------------------------------------------------------------
[1/6] Testing: Single GPU (baseline)
  Cluster: 1 xPUs (TP=1, PP=1, DP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
✗ Failed

-----------------------------------------------------------------------
[2/6] Testing: TP=2
  Cluster: 2 xPUs (TP=2, PP=1, DP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 55

Throughput:
  Requests/sec: 0.92
  Tokens/sec: 118.06

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.91GB / 80GB ( 99.9%)
  P95:         79.83GB / 80GB ( 99.8%)
  P50 (Med):   74.23GB / 80GB ( 92.8%)

First Token Latency (seconds):
  Mean: 27.4650
  P50:  28.6921
  P90:  50.0082
  P95:  50.3055
  P99:  50.3980

End-to-End Latency (seconds):
  Mean: 28.2925
  P50:  28.7077
  P90:  46.7515
  P95:  49.1745
  P99:  50.3467

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_130356/config_2xpu_tp2_pp1_dp1.json
✓ Completed successfully
  Throughput: 118.1 tok/s, Completed: 55, P95 TTFT: 50.31s

-----------------------------------------------------------------------
[3/6] Testing: TP=4
  Cluster: 4 xPUs (TP=4, PP=1, DP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 172

Throughput:
  Requests/sec: 2.87
  Tokens/sec: 376.00

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.80GB / 80GB ( 99.7%)
  P95:         79.75GB / 80GB ( 99.7%)
  P50 (Med):   63.30GB / 80GB ( 79.1%)

First Token Latency (seconds):
  Mean: 21.1883
  P50:  20.2642
  P90:  38.2319
  P95:  39.1525
  P99:  39.8194

End-to-End Latency (seconds):
  Mean: 23.3217
  P50:  23.8108
  P90:  38.2885
  P95:  39.2102
  P99:  41.1309

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_130356/config_4xpu_tp4_pp1_dp1.json
✓ Completed successfully
  Throughput: 376.0 tok/s, Completed: 172, P95 TTFT: 39.15s

-----------------------------------------------------------------------
[4/6] Testing: TP=8
  Cluster: 8 xPUs (TP=8, PP=1, DP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.00s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 257

Throughput:
  Requests/sec: 4.28
  Tokens/sec: 579.31

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.98GB / 80GB (100.0%)
  P95:         79.49GB / 80GB ( 99.4%)
  P50 (Med):   55.71GB / 80GB ( 69.6%)

First Token Latency (seconds):
  Mean: 14.7476
  P50:  14.9555
  P90:  27.2447
  P95:  28.0583
  P99:  29.2115

End-to-End Latency (seconds):
  Mean: 17.7456
  P50:  18.5166
  P90:  28.9388
  P95:  30.1586
  P99:  31.6511

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_130356/config_8xpu_tp8_pp1_dp1.json
✓ Completed successfully
  Throughput: 579.3 tok/s, Completed: 257, P95 TTFT: 28.06s

-----------------------------------------------------------------------
[5/6] Testing: TP=4, PP=2
  Cluster: 8 xPUs (TP=4, PP=2, DP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 172

Throughput:
  Requests/sec: 2.87
  Tokens/sec: 376.00

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.80GB / 80GB ( 99.7%)
  P95:         79.75GB / 80GB ( 99.7%)
  P50 (Med):   63.30GB / 80GB ( 79.1%)

First Token Latency (seconds):
  Mean: 21.1883
  P50:  20.2642
  P90:  38.2319
  P95:  39.1525
  P99:  39.8194

End-to-End Latency (seconds):
  Mean: 23.3217
  P50:  23.8108
  P90:  38.2885
  P95:  39.2102
  P99:  41.1309

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_130356/config_8xpu_tp4_pp2_dp1.json
✓ Completed successfully
  Throughput: 376.0 tok/s, Completed: 172, P95 TTFT: 39.15s

-----------------------------------------------------------------------
[6/6] Testing: TP=2, PP=2, DP=2
  Cluster: 8 xPUs (TP=2, PP=2, DP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 562
  Completed: 55

Throughput:
  Requests/sec: 0.92
  Tokens/sec: 118.06

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.91GB / 80GB ( 99.9%)
  P95:         79.83GB / 80GB ( 99.8%)
  P50 (Med):   74.23GB / 80GB ( 92.8%)

First Token Latency (seconds):
  Mean: 27.4650
  P50:  28.6921
  P90:  50.0082
  P95:  50.3055
  P99:  50.3980

End-to-End Latency (seconds):
  Mean: 28.2925
  P50:  28.7077
  P90:  46.7515
  P95:  49.1745
  P99:  50.3467

============================================================

✓ Results saved to: results/cluster_benchmark_20251208_130356/config_8xpu_tp2_pp2_dp2.json
✓ Completed successfully
  Throughput: 118.1 tok/s, Completed: 55, P95 TTFT: 50.31s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (월) 13:03:58 PST

==============================================================================================================
CLUSTER CONFIGURATION BENCHMARK REPORT
==============================================================================================================

Fixed Configuration:
--------------------------------------------------------------------------------------------------------------
  Model:           llama2-70b
  xPU:             a100-80gb
  Workload:        10.0 req/s arrival rate
  Input Length:    avg=512, max=1024
  Output Length:   avg=128, max=256
  Duration:        60.0s
  Random Seed:     4088

Performance by Cluster Configuration:
==============================================================================================================
#xPUs    TP     PP     DP     Throughput         Completed    P95 TTFT     Memory       Util    
--------------------------------------------------------------------------------------------------------------
2        2      1      1              118.1 tok/s     55/562      50.31s      79.9GB   100.0%
4        4      1      1              376.0 tok/s    172/562      39.15s      79.8GB   100.0%
8        2      2      2              118.1 tok/s     55/562      50.31s      79.9GB   100.0%
8        4      2      1              376.0 tok/s    172/562      39.15s      79.8GB   100.0%
8        8      1      1              579.3 tok/s    257/562      28.06s      80.0GB   100.0%
--------------------------------------------------------------------------------------------------------------

Key Insights:
--------------------------------------------------------------------------------------------------------------
  Best Configuration:
    8 xPUs (TP=8, PP=1, DP=1)
    Throughput: 579.3 tok/s
    Completed: 257/562 (45.7%)

  Speedup vs Baseline (2 xPU):
    4 xPUs (TP=4, PP=1, DP=1): 3.18x speedup, 159.2% scaling efficiency
    8 xPUs (TP=2, PP=2, DP=2): 1.00x speedup, 25.0% scaling efficiency
    8 xPUs (TP=4, PP=2, DP=1): 3.18x speedup, 79.6% scaling efficiency
    8 xPUs (TP=8, PP=1, DP=1): 4.91x speedup, 122.7% scaling efficiency

  Memory Usage:
    2 xPUs (TP=2): 79.9GB total, 40.0GB per xPU
    4 xPUs (TP=4): 79.8GB total, 19.9GB per xPU
    8 xPUs (TP=2): 79.9GB total, 10.0GB per xPU
    8 xPUs (TP=4): 79.8GB total, 10.0GB per xPU
    8 xPUs (TP=8): 80.0GB total, 10.0GB per xPU

==============================================================================================================

Results saved to: results/cluster_benchmark_20251208_130356
Log file: results/cluster_benchmark_20251208_130356/benchmark.log
=======================================================================
