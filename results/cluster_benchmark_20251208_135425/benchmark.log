=======================================================================
LLM Inference Simulator - TP Scaling Benchmark
=======================================================================
Start Time: 2025. 12. 08. (Ïõî) 13:54:25 PST
Random Seed: 18009

‚ö†Ô∏è  Note: Only TP (Tensor Parallelism) is implemented

Configuration:
  Model:           llama2-70b
  xPUs:            a100-80gb h100-80gb mi300x
  Arrival Rate:    10.0 req/s
  Duration:        60.0s

Testing 3 xPUs √ó 4 TP configs = 12 total tests
=======================================================================

-----------------------------------------------------------------------
[1/12] Testing: a100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[2/12] Testing: a100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.03s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 61

Throughput:
  Requests/sec: 1.02
  Tokens/sec: 125.60

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.78GB / 80GB ( 99.7%)
  P50 (Med):   75.74GB / 80GB ( 94.7%)

First Token Latency (seconds):
  Mean: 27.4314
  P50:  28.3011
  P90:  49.4570
  P95:  49.6866
  P99:  49.8504

End-to-End Latency (seconds):
  Mean: 30.9202
  P50:  31.9534
  P90:  48.9912
  P95:  53.3801
  P99:  54.4720

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/a100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 125.6 tok/s, Completed: 61, P95 TTFT: 49.69s

-----------------------------------------------------------------------
[3/12] Testing: a100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.03s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 173

Throughput:
  Requests/sec: 2.88
  Tokens/sec: 378.28

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.93GB / 80GB ( 99.9%)
  P95:         78.98GB / 80GB ( 98.7%)
  P50 (Med):   66.01GB / 80GB ( 82.5%)

First Token Latency (seconds):
  Mean: 22.6145
  P50:  21.7763
  P90:  41.4633
  P95:  41.9062
  P99:  42.3836

End-to-End Latency (seconds):
  Mean: 23.8674
  P50:  23.1550
  P90:  39.7579
  P95:  40.8361
  P99:  42.0651

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/a100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 378.3 tok/s, Completed: 173, P95 TTFT: 41.91s

-----------------------------------------------------------------------
[4/12] Testing: a100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.03s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 261

Throughput:
  Requests/sec: 4.35
  Tokens/sec: 575.36

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.91GB / 80GB ( 99.9%)
  P95:         79.51GB / 80GB ( 99.4%)
  P50 (Med):   62.74GB / 80GB ( 78.4%)

First Token Latency (seconds):
  Mean: 17.6793
  P50:  17.3863
  P90:  31.3290
  P95:  32.8839
  P99:  34.2696

End-to-End Latency (seconds):
  Mean: 20.1672
  P50:  20.2583
  P90:  32.6336
  P95:  33.8815
  P99:  35.3601

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/a100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 575.4 tok/s, Completed: 261, P95 TTFT: 32.88s

-----------------------------------------------------------------------
[5/12] Testing: h100-80gb - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 219, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 203, in main
    config = create_config_from_args(args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/cli.py", line 83, in create_config_from_args
    return SimulatorConfig(
           ^^^^^^^^^^^^^^^^
  File "<string>", line 12, in __init__
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 113, in __post_init__
    self.validate()
  File "/home/deckerd/my_projects/inference_sim/llm_inference_simulator/config.py", line 203, in validate
    raise ValueError(error_msg.strip())
ValueError: Configuration validation failed:
  1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
‚úó Failed
  Error: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.

-----------------------------------------------------------------------
[6/12] Testing: h100-80gb - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 14.81GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 109

Throughput:
  Requests/sec: 1.82
  Tokens/sec: 227.96

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.59GB / 80GB ( 99.5%)
  P50 (Med):   75.74GB / 80GB ( 94.7%)

First Token Latency (seconds):
  Mean: 25.7528
  P50:  26.1374
  P90:  44.9934
  P95:  48.7878
  P99:  49.2914

End-to-End Latency (seconds):
  Mean: 26.8997
  P50:  26.2798
  P90:  45.5115
  P95:  48.5137
  P99:  49.6761

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/h100-80gb_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 228.0 tok/s, Completed: 109, P95 TTFT: 48.79s

-----------------------------------------------------------------------
[7/12] Testing: h100-80gb - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 47.40GB available for KV cache

Simulation completed at t=60.72s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 337

Throughput:
  Requests/sec: 5.55
  Tokens/sec: 701.13

xPU Utilization: 100.0%

Memory Usage:
  Peak:        79.89GB / 80GB ( 99.9%)
  P95:         79.20GB / 80GB ( 99.0%)
  P50 (Med):   63.18GB / 80GB ( 79.0%)

First Token Latency (seconds):
  Mean: 14.0748
  P50:  14.5594
  P90:  24.2853
  P95:  25.2613
  P99:  26.2012

End-to-End Latency (seconds):
  Mean: 16.8015
  P50:  17.5021
  P90:  27.0044
  P95:  28.2299
  P99:  29.3228

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/h100-80gb_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 701.1 tok/s, Completed: 337, P95 TTFT: 25.26s

-----------------------------------------------------------------------
[8/12] Testing: h100-80gb - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 63.70GB available for KV cache

Simulation completed at t=60.02s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 474

Throughput:
  Requests/sec: 7.90
  Tokens/sec: 1039.52

xPU Utilization: 100.0%

Memory Usage:
  Peak:        80.00GB / 80GB (100.0%)
  P95:         79.54GB / 80GB ( 99.4%)
  P50 (Med):   56.76GB / 80GB ( 70.9%)

First Token Latency (seconds):
  Mean: 7.1282
  P50:  7.3814
  P90:  11.6809
  P95:  12.4161
  P99:  13.6003

End-to-End Latency (seconds):
  Mean: 9.5470
  P50:  9.9044
  P90:  14.1092
  P95:  14.9376
  P99:  16.2657

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/h100-80gb_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1039.5 tok/s, Completed: 474, P95 TTFT: 12.42s

-----------------------------------------------------------------------
[9/12] Testing: mi300x - TP=1
  Cluster: 1 xPUs (TP=1)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 1 xPUs, arrival_rate=10.0 req/s
Memory: 130.39GB model, 61.61GB available for KV cache

Simulation completed at t=60.40s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 216

Throughput:
  Requests/sec: 3.58
  Tokens/sec: 443.29

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.70GB / 192GB ( 99.8%)
  P95:        191.38GB / 192GB ( 99.7%)
  P50 (Med):  173.31GB / 192GB ( 90.3%)

First Token Latency (seconds):
  Mean: 19.7074
  P50:  21.2348
  P90:  34.5943
  P95:  35.1407
  P99:  35.5548

End-to-End Latency (seconds):
  Mean: 23.6111
  P50:  23.8617
  P90:  38.4496
  P95:  39.8574
  P99:  40.7249

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/mi300x_1xpu_tp1.json
‚úì Completed successfully
  Throughput: 443.3 tok/s, Completed: 216, P95 TTFT: 35.14s

-----------------------------------------------------------------------
[10/12] Testing: mi300x - TP=2
  Cluster: 2 xPUs (TP=2)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 2 xPUs, arrival_rate=10.0 req/s
Memory: 65.19GB model, 126.81GB available for KV cache

Simulation completed at t=62.52s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 458

Throughput:
  Requests/sec: 7.33
  Tokens/sec: 934.30

xPU Utilization: 100.0%

Memory Usage:
  Peak:       191.94GB / 192GB (100.0%)
  P95:        191.76GB / 192GB ( 99.9%)
  P50 (Med):  137.21GB / 192GB ( 71.5%)

First Token Latency (seconds):
  Mean: 9.1907
  P50:  9.1591
  P90:  14.4543
  P95:  15.4069
  P99:  17.0619

End-to-End Latency (seconds):
  Mean: 13.1600
  P50:  13.4981
  P90:  18.8357
  P95:  20.0956
  P99:  21.0968

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/mi300x_2xpu_tp2.json
‚úì Completed successfully
  Throughput: 934.3 tok/s, Completed: 458, P95 TTFT: 15.41s

-----------------------------------------------------------------------
[11/12] Testing: mi300x - TP=4
  Cluster: 4 xPUs (TP=4)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 4 xPUs, arrival_rate=10.0 req/s
Memory: 32.60GB model, 159.40GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 582

Throughput:
  Requests/sec: 9.70
  Tokens/sec: 1229.43

xPU Utilization: 100.0%

Memory Usage:
  Peak:       128.86GB / 192GB ( 67.1%)
  P95:        117.31GB / 192GB ( 61.1%)
  P50 (Med):   72.95GB / 192GB ( 38.0%)

First Token Latency (seconds):
  Mean: 3.1950
  P50:  3.0918
  P90:  5.1309
  P95:  5.4933
  P99:  6.0750

End-to-End Latency (seconds):
  Mean: 5.5395
  P50:  5.5889
  P90:  7.9454
  P95:  8.3712
  P99:  9.0212

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/mi300x_4xpu_tp4.json
‚úì Completed successfully
  Throughput: 1229.4 tok/s, Completed: 582, P95 TTFT: 5.49s

-----------------------------------------------------------------------
[12/12] Testing: mi300x - TP=8
  Cluster: 8 xPUs (TP=8)
-----------------------------------------------------------------------

Starting simulation...
Starting simulation...
Configuration: LLaMA-2-70B, 8 xPUs, arrival_rate=10.0 req/s
Memory: 16.30GB model, 175.70GB available for KV cache

Simulation completed at t=60.01s

============================================================
SIMULATION SUMMARY
============================================================

Requests:
  Total: 631
  Completed: 602

Throughput:
  Requests/sec: 10.03
  Tokens/sec: 1281.39

xPU Utilization: 100.0%

Memory Usage:
  Peak:        66.80GB / 192GB ( 34.8%)
  P95:         55.53GB / 192GB ( 28.9%)
  P50 (Med):   34.99GB / 192GB ( 18.2%)

First Token Latency (seconds):
  Mean: 1.2585
  P50:  1.2285
  P90:  2.1276
  P95:  2.3420
  P99:  2.6556

End-to-End Latency (seconds):
  Mean: 2.4269
  P50:  2.4146
  P90:  3.4831
  P95:  3.7543
  P99:  4.1006

============================================================

‚úì Results saved to: results/cluster_benchmark_20251208_135425/mi300x_8xpu_tp8.json
‚úì Completed successfully
  Throughput: 1281.4 tok/s, Completed: 602, P95 TTFT: 2.34s

=======================================================================
Benchmark Complete!
=======================================================================
End Time: 2025. 12. 08. (Ïõî) 13:54:32 PST

========================================================================================================================
TP SCALING BENCHMARK REPORT
========================================================================================================================

Configuration:
------------------------------------------------------------------------------------------------------------------------
  Model:           N/A
  xPUs Tested:     N/A
  Workload:        N/A req/s
  Duration:        N/As

Performance by xPU and TP Configuration:
========================================================================================================================
xPU             #xPUs    TP     Status       Throughput         Completed    P95 TTFT    
------------------------------------------------------------------------------------------------------------------------
a100-80gb       1        1      ‚ùå FAILED     N/A                N/A          N/A         
a100-80gb       2        2      ‚úÖ SUCCESS            125.6 tok/s     61/631      49.69s
a100-80gb       4        4      ‚úÖ SUCCESS            378.3 tok/s    173/631      41.91s
a100-80gb       8        8      ‚úÖ SUCCESS            575.4 tok/s    261/631      32.88s
h100-80gb       1        1      ‚ùå FAILED     N/A                N/A          N/A         
h100-80gb       2        2      ‚úÖ SUCCESS            228.0 tok/s    109/631      48.79s
h100-80gb       4        4      ‚úÖ SUCCESS            701.1 tok/s    337/631      25.26s
h100-80gb       8        8      ‚úÖ SUCCESS           1039.5 tok/s    474/631      12.42s
mi300x          1        1      ‚úÖ SUCCESS            443.3 tok/s    216/631      35.14s
mi300x          2        2      ‚úÖ SUCCESS            934.3 tok/s    458/631      15.41s
mi300x          4        4      ‚úÖ SUCCESS           1229.4 tok/s    582/631       5.49s
mi300x          8        8      ‚úÖ SUCCESS           1281.4 tok/s    602/631       2.34s
------------------------------------------------------------------------------------------------------------------------

üí∞ Cost Efficiency Analysis:
========================================================================================================================
xPU             Config       $/hour     Throughput      Tok/$/hour      Cost/1M tok 
------------------------------------------------------------------------------------------------------------------------
MI300X          2√óTP2        $14.00           934.3 tok/s          66.7  $  14984.51
MI300X          1√óTP1        $7.00            443.3 tok/s          63.3  $  15791.05
MI300X          4√óTP4        $28.00          1229.4 tok/s          43.9  $  22774.77
H100-80GB       4√óTP4        $25.96           701.1 tok/s          27.0  $  37025.94
A100-80GB       4√óTP4        $14.68           378.3 tok/s          25.8  $  38807.16
MI300X          8√óTP8        $56.00          1281.4 tok/s          22.9  $  43702.39
H100-80GB       8√óTP8        $51.92          1039.5 tok/s          20.0  $  49946.08
A100-80GB       8√óTP8        $29.36           575.4 tok/s          19.6  $  51028.70
H100-80GB       2√óTP2        $12.98           228.0 tok/s          17.6  $  56940.82
A100-80GB       2√óTP2        $7.34            125.6 tok/s          17.1  $  58438.76
------------------------------------------------------------------------------------------------------------------------

üèÜ Recommended Configurations:
------------------------------------------------------------------------------------------------------------------------
  üí∞ Best Value (Cost Efficiency):
     MI300X 2√óTP2
     66.7 tok/$/hour | $14984.51/1M tokens | $14.00/hour

  üöÄ Best Performance (Throughput):
     MI300X 8√óTP8
     1281.4 tok/s | P95 TTFT: 2.34s | $56.00/hour

  ‚ö° Best Latency (TTFT):
     MI300X 8√óTP8
     P95 TTFT: 2.34s | 1281.4 tok/s | $56.00/hour


‚ùå Failed Tests:
------------------------------------------------------------------------------------------------------------------------
  A100-80GB       TP=1 (1 xPUs):
    Reason: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.
  H100-80GB       TP=1 (1 xPUs):
    Reason: 1. Model weights (130.39GB per xPU with TP=1) exceed xPU memory (80.0GB). Increase tensor_parallel_size or use larger xPUs.


üìà TP Scaling Efficiency:
------------------------------------------------------------------------------------------------------------------------
  A100-80GB:
    TP= 4 (4 xPUs): 3.01x speedup, 150.6% efficiency (ideal: 2.0x)
    TP= 8 (8 xPUs): 4.58x speedup, 114.5% efficiency (ideal: 4.0x)

  H100-80GB:
    TP= 4 (4 xPUs): 3.08x speedup, 153.8% efficiency (ideal: 2.0x)
    TP= 8 (8 xPUs): 4.56x speedup, 114.0% efficiency (ideal: 4.0x)

  MI300X:
    TP= 2 (2 xPUs): 2.11x speedup, 105.4% efficiency (ideal: 2.0x)
    TP= 4 (4 xPUs): 2.77x speedup, 69.3% efficiency (ideal: 4.0x)
    TP= 8 (8 xPUs): 2.89x speedup, 36.1% efficiency (ideal: 8.0x)

========================================================================================================================
Summary: 10 succeeded, 2 failed
========================================================================================================================

Results saved to: results/cluster_benchmark_20251208_135425
=======================================================================
